% Koma class
\documentclass[a4paper, oneside]{scrartcl}   

\usepackage{a4wide}
\usepackage{german}

%------------------
% language = english
\usepackage[english]{babel}	% Umlaute mit \"u
\usepackage[latin1]{inputenc}

% margins + Kopf- und Fußzeilen
\usepackage[left = 2.5cm, right = 2.5cm, top = 2cm, bottom = 3cm]{geometry}
\usepackage{scrpage2} 
\pagestyle{scrheadings}
\clearscrheadfoot
\rehead{\headmark}
\lehead{\pagemark}
\lohead{\headmark}
\rohead{\pagemark} 


% math
\usepackage{amssymb}
\usepackage{amsmath}

% figures
\usepackage{tikz}
\usepackage{graphicx}


% section-Zaehler wird neu gesetzt:
\setcounter{section}{1}
%------------------
\author{Sascha Meiers, Martin Seeger}
\title{Exercise 1, Discrete Mathematics for Bioinformatics}
\date{Winter term 2011/2012}


\begin{document}
\maketitle

%---------------------------------------------------------------------------------------------------

\subsection{MST Approximation}

a) The following complete graph with six nodes satisfies the triangle
inequality. Marked in red are the edges that are selected by the Kruskal
algorithm.
\\

\begin{figure}
\begin{tikzpicture}
% Default actions for each node
\tikzstyle{every node}=[draw];
\tikzstyle{edge} = [draw,thick,-]
\tikzstyle{weight} = [font=\tiny, draw=none, fill=none]
% Define and draw five nodes
\node [shape=circle] (v1) at (0:4) {$v_1$};
\node [shape=circle] (v2) at (60:4) {$v_2$};
\node [shape=circle] (v3) at (120:4) {$v_3$};
\node [shape=circle] (v4) at (180:4) {$v_4$};
\node [shape=circle] (v5) at (240:4) {$v_5$};
\node [shape=circle] (v6) at (300:4) {$v_6$};
% Draw radial edges
\draw 
(v1) [color=red] -- node[weight, label=right:\footnotesize 1] {} (v2)
(v2) -- node[weight, label=above:\footnotesize 1] {} (v3)
(v3) -- node[weight, label=left:\footnotesize 1] {} (v4)
(v4) -- node[weight, label=left:\footnotesize 1] {} (v5)
(v5) -- node[weight, label=below:\footnotesize 1] {} (v6);
\draw 
(v6) [color=black] -- node[weight, label=right:\footnotesize 1] {} (v1)

(v1) -- node[weight, right=1ex] {\footnotesize 3} (v3) 
(v4) -- node[weight, left=1ex] {\footnotesize 3} (v2) 
(v3) -- node[weight, above left=0.25ex] {\footnotesize 3} (v5) 
(v4) -- node[weight, left=1ex] {\footnotesize 3} (v6) 
(v5) -- node[weight, right=1ex] {\footnotesize 3} (v1) 
(v6) -- node[weight, above right=0.25ex] {\footnotesize 3} (v2) 

(v1) -- node[weight, right=6ex, above=0.25ex] {\footnotesize 5} (v4) 
(v2) -- node[weight, right=1ex, above=3ex] {\footnotesize 5} (v5)
(v3) -- node[weight, left=1ex, above=3ex] {\footnotesize 5} (v6)
;
\end{tikzpicture}
\end{figure}

The following algorithm (borrowed from Wikipedia) delivers a 2-approximation:
\begin{enumerate}
  \item Construct the minimum spanning tree.
  \item Duplicate all its edges. This gives us an Eulerian graph.
  \item Find a Eulerian cycle in it. Clearly, its length is twice the length of
  the tree. 
  \item Convert the Eulerian cycle into the Hamiltonian one in the following
  way: walk along the Eulerian cycle, and each time you are about to come into
  an already visited vertex, skip it and try to go to the next one (along the
  Eulerian cycle).
\end{enumerate}
    
Carrying out this algorithm on the above graph visits the vertices in the
following order: 
\begin{eqnarray}
& & v_1 \rightarrow v_2 \rightarrow v_3 \rightarrow v_4
\rightarrow v_5 \rightarrow v_6\nonumber \\
& & \rightarrow v_5\ {\rm (skipped)} \rightarrow
v_4\ {\rm (skipped)} \rightarrow v_3\ {\rm (skipped)} \rightarrow v_2\ {\rm
(skipped)} \rightarrow v_1.\nonumber 
\end{eqnarray}
The resulting approximation to the TSP is displayed below. It happens to be the
exact solution.
\begin{figure}
\begin{tikzpicture}
% Default actions for each node
\tikzstyle{every node}=[draw];
\tikzstyle{edge} = [draw,thick,-]
\tikzstyle{weight} = [font=\tiny, draw=none, fill=none]
% Define and draw five nodes
\node [shape=circle] (v1) at (0:4) {$v_1$};
\node [shape=circle] (v2) at (60:4) {$v_2$};
\node [shape=circle] (v3) at (120:4) {$v_3$};
\node [shape=circle] (v4) at (180:4) {$v_4$};
\node [shape=circle] (v5) at (240:4) {$v_5$};
\node [shape=circle] (v6) at (300:4) {$v_6$};
% Draw radial edges
\draw 
(v1) [color=green] -- node[weight, label=right:\footnotesize 1] {} (v2)
(v2) -- node[weight, label=above:\footnotesize 1] {} (v3)
(v3) -- node[weight, label=left:\footnotesize 1] {} (v4)
(v4) -- node[weight, label=left:\footnotesize 1] {} (v5)
(v5) -- node[weight, label=below:\footnotesize 1] {} (v6)
(v6) -- node[weight, label=right:\footnotesize 1] {} (v1);
\draw 
(v1) -- node[weight, right=1ex] {\footnotesize 3} (v3) 
(v4) -- node[weight, left=1ex] {\footnotesize 3} (v2) 
(v3) -- node[weight, above left=0.25ex] {\footnotesize 3} (v5) 
(v4) -- node[weight, left=1ex] {\footnotesize 3} (v6) 
(v5) -- node[weight, right=1ex] {\footnotesize 3} (v1) 
(v6) -- node[weight, above right=0.25ex] {\footnotesize 3} (v2) 

(v1) -- node[weight, right=6ex, above=0.25ex] {\footnotesize 5} (v4) 
(v2) -- node[weight, right=1ex, above=3ex] {\footnotesize 5} (v5)
(v3) -- node[weight, left=1ex, above=3ex] {\footnotesize 5} (v6)
;
\end{tikzpicture}
\end{figure}

\noindent b) A 2-approximation is worse by at most a factor of two than the
optimal solution for any input (i.e. for any graph). The Eulerian trail constructed in the
intermediate step has two times the weight of a minimal spanning tree. By
repeatedly taking shortcuts, its weight can only be reduced, hence
\[
w({\rm approximation}) \leq w({\rm Eulerian\ trail}) = 2 w({\rm MST}) \leq 2
w({\rm optimal\ solution}).\square
\] 


\subsection{Landau Symbols}

\renewcommand{\labelenumi}{\alph{enumi})}
\begin{enumerate}
\item Let $k, l \in \mathbb{Z}$, $k > l$. $f = o(g)$ holds iff 
\begin{equation}
\lim_{n\rightarrow \infty} \left|\frac{f(n)}{g(n)}\right| = 0. 
\end{equation}
In our case, 
\begin{equation}
\lim_{n\rightarrow \infty} \left|\frac{f(n)}{g(n)}\right| = \lim_{n\rightarrow
\infty} \left|\frac{n^l}{n^k}\right| = \lim_{n\rightarrow
\infty} \left|\frac{1}{n^{k-l}}\right| = 0,
\end{equation}
whence it follows that $n^l=o(n^k)$.$\square$

\item Let $k, l \in \mathbb{N}$, $k > l$. In general, $f=\Theta(g)$ iff
$f=O(g)$ and $g=O(f)$. We use the definition $f=O(g)$ iff
\begin{equation}
0 \leq \limsup_{n\rightarrow \infty} \left|\frac{f(n)}{g(n)}\right| < \infty. 
\end{equation}
In our case, 
\begin{equation}
\limsup_{n\rightarrow \infty} \left|\frac{n^k+n^l}{n^k}\right| =
\limsup_{n\rightarrow \infty} \left|1 + \frac{1}{n^{k-l}}\right| = 1,
\end{equation}
and
\begin{equation}
\limsup_{n\rightarrow \infty} \left|\frac{n^k}{n^k+n^l}\right| =
\limsup_{n\rightarrow \infty} \left|1 - \frac{n^l}{n^k+n^l}\right| =
\limsup_{n\rightarrow \infty} \left|1 - \frac{1}{n^{k-l}+1}\right| =
1.\square
\end{equation}
 
\item Counterexample: $f(n)=2^{cn}$ with $c>1$ is clearly $2^{O(n)}$. However, 
\begin{equation}
\limsup_{n\rightarrow \infty} \left|\frac{2^{cn}}{2^{n}}\right| =
\limsup_{n\rightarrow \infty} 2^{(c-1)n} = \infty,
\end{equation}
hence $f \neq O(2^n)$.$\square$
\end{enumerate}


\subsection{Amortized Analysis}

x


\subsection{Analysis of \textsc{Select} algorithm}

The \textsc{Select} algorithm is given a list $A$ of $n$ numbers (or elements of a completely ordered universe) 
and a rank $k\leq n$. It returns the $k$-th smallest element of $A$.

The deterministic \textsc{Select} algorithm guarantees a worst-case complexity of $\mathcal{O}(n)$ by smartly choosing a Pivot element. 
This is achieved by dividing the elements of the list into groups of 5 
(in general $r$, meaning \textit{row} as related to the figure) and calculating the medians of each group in constant time 
(since a group contains only constant many elements). The same routine is used recursively to determine the median of these medians. 
Finally the whole list is split up like in Quicksort, using the median of medians for Pivot element, and the search is continued in 
only one of both parts depending on $k$. As is shown in the additional material, splitting at this point drops always enough elements for the runtime to be linear in $n$. Here we want to investigate wether the linear-time property holds for other values of $r$, too.

The runtime of the \textsc{Select} algorithm can be written recursively as 
\[ T(n) = T(\left\lceil \frac{n}{r} \right\rceil ) + T(g(n)) + an \]
\begin{itemize}
\item $T(\left\lceil \frac{n}{r} \right\rceil)$ is the runtime for the recursive call of \textsc{Select} in order to 
compute the median of medians. 
\item $c\cdot n$ is the runtime of dividing the list into groups of $r$, finding their 
medians (which works in $\mathcal{O}(r\; log\; r)$, i.e. in $\mathcal{O}(1)$ for each group) and finally splitting up the list.
\item $T(g(n))$ is the runtime of the recursive call of \textsc{Select} on a smaller list. $g(n)$ is an upper bound for the 
length of this list and by association the key variant in enabling a linear overall runtime. For $r=5$ we've seen that 
$g(n) \leq \frac{7}{10} n + 6 $.
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=10cm]{deterministic_select.pdf}
\end{figure}

The figure shows the partial ordering we obtain by determining the median of medians. At least the elements in the lower 
right box are larger than or equal to the Pivot element $x$, but there can be more in the upper right or lower left quarter. 
On the other side there is at least the upper left quarter of elements that are lower than or equal to $x$. Let's assume $r$ 
to be odd (since we then can clearly determine a median). Then the lower right quarter consists of 
$\left\lceil \frac{n}{2r} \right\rceil$ columns with each $\frac{r+1}{2}$ elements except for the last columns, wich contains 
at least one element. So we will not count the last column and we will also deduct the column of $x$ itself (the same is done in the additional material). So the maximum number of elements in the next recursive call for an odd number $r$ is

\begin{align*}
g(n) &\leq n - \left( \left\lceil \frac{n}{2r} \right\rceil -2\right) \cdot \frac{r+1}{2}\\
     &\leq n - \left( \frac{n}{2r} -2\right) \cdot \frac{r+1}{2}\\
     &\leq (0.75 - \frac{1}{4r})\cdot n +(r+1) .
\end{align*}
Due to monotonicity of the runtime function, $T(n)$ is now determined by
\begin{align*}
T(n) &\leq T\left( \frac{n}{r} +1 \right) + T\left( (0.75 - \frac{1}{4r})\cdot n +(r+1) \right) + an 
\end{align*}
Now assume that $T(n) \leq c\cdot n$ for large $n$ and a constant factor $c$. Then we have
\begin{align*}
T(n) &\leq c\cdot \left( \frac{n}{r} \right) +c + c\cdot \left( (0.75 - \frac{1}{4r})\cdot n +(r+1) \right) + an \\
     & =    cn \left(\frac{1}{r} + 0.75 - \frac{1}{4r}\right) + an + (r+2)c \\
     & = cn - cn \left(\frac{r-3}{4r}\right) + an + (r+2)c
\end{align*}
In order to complete the proof, we have to show that this recursively defined runtime is at most $cn$, too. 
This depends on the term after $cn$: If it is at most zero, the runtime is linear.
We have to differ two cases: If $r\leq 3$, then there are only positive addends in the term and the inequality obviously does not hold. 
Otherwise, if $r>3$, the fraction $\frac{r-3}{4r}$ is larger than zero but less than one and we can find the factor $c$ as needed: 
\begin{align*}
- cn \left(\frac{r-3}{4r}\right) + an + (r+2)c &\leq 0 \\
c \left( -n\frac{r-3}{4r} +r +2 \right) &\leq -an \\
c &\geq \frac{an} { n\frac{r-3}{4r} -r -2 }		\qquad \| \; \text{for } n > r+2
\end{align*}
This inequality can be solved for any $r>3$, if $n$ is chosen large enough (for example $n> 2(r+2)$). If we choose $r=5$, 
we can exactly reproduce the example from the additional material:
\begin{align*}
c &\geq \frac{an} { n\frac{5-3}{4\cdot 5} -5 -2 }		& \| \; \text{for } n > 5+2 \\
c &\geq \frac{10an} {n - 70}  & \\ 
c &\geq 20a 					& \| \; \text{for } n>140\text{, because } \frac{n}{n-70}\leq 2
\end{align*}
Finally we found a constant factors $c$ (which of course depends on the factor $a$ for splitting the list etc.) such that the overall runtime is linear. During the derivation we found that the linear runtime only works for $r>3$, which answers the initial question.





\end{document}


\begin{document}
\maketitle

%\section{Title}

\end{document}